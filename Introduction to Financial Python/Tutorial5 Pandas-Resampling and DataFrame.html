<h2>Introduction</h2>
In the last chapter we had a glimpse of Pandas. In this chapter we will learn resampling methods and DataFrame manipulating with real financial data. DataFrame is a very powerful tool for data analysis, and we will cover some commonly used methods dealing with financial data.

Here we use the data from yahoo_finance API.
<pre class="prettyprint linenums">import quandl
quandl.ApiConfig.api_key = 'dRQxJ15_2nrLznxr1Nn4'
aapl_table = quandl.get('WIKI/AAPL')
aapl = aapl_table['Adj. Close']['2017']
</pre>
<h2>Resampling</h2>
Last time we discussed how to access to series data by date index. Let's start from here using real financial time series data. aapl is a series who's values are Apple stock's daily close price, and the index is date. We will introduce how to obtain this series later.
<pre class="prettyprint linenums">print aapl
</pre>
We have already known that we can access to a specific data point using series['yyyy-mm-dd']. We can also get access to the data in a specific month by simply using series['yyyy-mm'].
<pre class="prettyprint linenums">print aapl['2017-3']
</pre>
Or in some consecutive months:
<pre class="prettyprint linenums">aapl['2017-2':'2017-4']
</pre>
seires.head() and series.tail() are also useful method to quickly get access to the first or last N elements.
<pre class="prettyprint linenums">print aapl.head(5)
print aapl.tail(10)
</pre>
Now we introduce a very powerful method: resample(). series.resample(freq) is a class called 'resampler'. The Argument freq tells the resampler the frequency for aggregating data. series.resample.mean() is a complete statement that aggregate the data by mean by a certain frequency. For example, if we want to aggregate the daily data into monthly data by mean:
<pre class="prettyprint linenums">by_month = aapl.resample('M').mean()
print by_month
</pre>
We can also aggregate the data by week:
<pre class="prettyprint linenums">by_week = aapl.resample('W').mean()
print by_week
</pre>
Virtually we can use almost any frequency we want by simply use the format 'nf', where 'n' is an integer and 'f' is M for month, W for week and D for day.
<pre class="prettyprint linenums">three_day = aapl.resample('3D').mean()
two_week = aapl.resample('2W').mean()
two_month = aapl.resample('2M').mean()
</pre>
We can also change the aggregating method. By default we can use mean(), std(), max(), min(), which are mean, standard deviation, maximum value and minimum value respectively.
<pre class="prettyprint linenums">std = aapl.resample('W').std()
max = aapl.resample('W').max()
min = aapl.resample('W').min()
</pre>
However, most of the time we don't want to aggregate in these methods. For example, if we want to calculate monthly return of the stock, we may just want to access the data for the last day of a month. Fortunately, we can customize the aggregating method. We write our function in series.resample.agg().
<pre class="prettyprint linenums">last_day = aapl.resample('M').agg(lambda x: x[-1])
print last_day
</pre>
Or directly calculate the monthly rates of return using the data for the first day and the last day:
<pre class="prettyprint linenums">monthly_return = aapl.resample('M').agg(lambda x: x[-1]/x[1] - 1)
print monthly_return
</pre>
Series object also provides us some convenient methods to do some quick calculation.
<pre class="prettyprint linenums">print monthly_return.mean()
print monthly_return.std()
print monthly_return.max()
</pre>
We can also check the statistical summaries of a series.
<pre class="prettyprint linenums">print aapl.describe()
</pre>
Another two frequently used method is series.diff() and series.pct_change(). This first method calculates the different between consecutive elements, and the second one calculates the percentage changes.
<pre class="prettyprint linenums">print last_day.diff()
print last_day.pct_change()
</pre>
You may noticed that we induced a NaN value while calculating the percentage change, or rate or return.
When dealing with NaN, we usually either removing the data point or fill it with a specific value. Here we fill it with value 0:
<pre class="prettyprint linenums">daily_return = last_day.pct_change()
print daily_return.fillna(0)
</pre>
We fill it with the next fitted value. This is called 'backward fill', or 'bfill' in short:
<pre class="prettyprint linenums">daily_return = last_day.pct_change()
print daily_return.fillna(method = 'bfill')
</pre>
As you expected, since there is a 'backward fill' method, there must be a 'forward fill' method, or 'ffill' in short. However we can't use it here because the NaN is the first value.
We can also simply remove the NaN data point by series.dropna().
<pre class="prettyprint linenums">daily_return = last_day.pct_change().dropna()
print daily_return
</pre>
<h2>DataFrame</h2>
After the long introduction to Series, finally we are going to discuss the most commonly used Pandas data structure: Pandas DataFrame. A DataFrame is essentially a group of series, thus it's not hard to understand how a DataFrames works if we master the series.

DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. You can think it like a spreadsheet or SQL table. Like series, DataFrame accepts many different kinds of input: dictionary, 2-D numpy.ndarray, a series and other DataFrame.
<h3>Create DataFrames</h3>
The most commonly used method to create a DataFrame is passing a data dictionary.
<pre class="prettyprint linenums">dict = {'AAPL': [143.5, 144.09, 142.73, 144.18, 143.77],'GOOG':[898.7, 911.71, 906.69, 918.59, 926.99],
        'IBM':[155.58, 153.67, 152.36, 152.94, 153.49]}
data_index = pd.date_range('2017-07-03',periods = 5, freq = 'D')
df = pd.DataFrame(dict, index = data_index)
print df
</pre>
<h3>Manipulating DataFrames</h3>
We can access to the values in a DataFrame by columns and index. Each columns in a DataFrame is essentially a pandas series. We can access to a column by square brackets df['column_name']. The columns names are also properties of the DataFrame, so we can also use df.column_name to get the columns. In the previous demonstration, we used exactly this method to access to the Apple stock close price series.
<pre class="prettyprint linenums">df = aapl_table
print df.Close.tail(5)
print df['Adj. Volume'].tail(5)
</pre>
All the methods we apply to a series index such as iloc[], loc[], and resampling methods, can also be applied to a DataFrame:
<pre class="prettyprint linenums">aapl_2016 = df['2016']
aapl_month = aapl_2016.resample('M').agg(lambda x: x[-1])
print aapl_month
</pre>
It's easy to access to multiple columns to form a subset of the original DataFrame:
<pre class="prettyprint linenums">aapl_bar = aapl_month[['Open', 'High', 'Low', Close']]
print aapl_bar
</pre>
We can also combined the methods above using loc[ ]. We separate the index and columns by comma to specify the range of data we want:
<pre class="prettyprint linenums">print aapl_month.loc['2016-03':'2016-06',['Open', 'High', 'Low', 'Close']]
</pre>
The subset methods in DataFrame is very powerful. By writing logical statements in square brackets, we can make customized subsets:
<pre class="prettyprint linenums">above = aapl_bar[aapl_bar.Close &gt; np.mean(aapl_bar.Close)]
print above</pre>
<h3>Data Validation</h3>
As we mentioned, all the series methods can be apply to a DataFrame in the same way. Here we create a new column from an existing DataFrame:
<pre class="prettyprint linenums">aapl_bar['rate_return'] = aapl_bar.Close.pct_change()
print aapl_bar
</pre>
Here the calculation introduced a NaN value. If the DataFrame is large, we would not be able to observe it. isnull() provides a convenient way to check abnormal values.
<pre class="prettyprint linenums">missing = aapl_bar.isnull()
print missing
print '------------------ separate line ------------'
print missing.describe()
</pre>
Note that the only column with value 2 in row 'unique' is 'rate_return'. This indicate that there are at least one missing value in the column 'rate_return'. We can even know the number of missing values by comparing 'count' and 'freq'. There are 12 counts and 11 'False', we know there is one 'True', which is the missing value.
We can also find the rows with missing values easily:
<pre class="prettyprint linenums">print missing[missing.rate_return == True]
</pre>
Usually when dealing with missing data, we either delete the whole row or fill it with some value. As we introduced in the series chapter, the same method df.dropna() and df.fillna() can be applied to a DataFrame.
<pre class="prettyprint linenums">drop = aapl_bar.dropna()
print drop
print '---------------------- separate ----------------------'
fill = aapl_bar.fillna(0)
print fill
</pre>
<h3>DataFrame Concat</h3>
We have already known how to extract a series from a dataFrame. Now we need to consider how to merge a series or a DataFrame into another one.
In Pandas, the function concat handles almost all of the merge tasks.
We can merge multiple series into a DataFrame:
<pre class="prettyprint linenums">s1 = pd.Series([143.5, 144.09, 142.73, 144.18, 143.77], name = 'AAPL')
s2 = pd.Series([898.7, 911.71, 906.69, 918.59, 926.99], name = 'GOOG')
data_frame = pd.concat([s1,s2], axis = 1)
print data_frame
</pre>
joining two DataFrames by axis:
<pre class="prettyprint linenums">log_price = np.log(aapl_bar.Close)
log_price.name = 'log_price'
print log_price
print '\n---------------------- separate line--------------------\n'
concat = pd.concat([aapl_bar, log_price], axis = 1)
print concat
When we joining a DataFrame into another, we can indicate whether we want to merge by index.</pre>
<pre class="prettyprint linenums">df_volume = aapl_table.loc['2016-10':'2017-04',['Volume', 'Split Ratio']].resample('M').agg(lambda x: x[-1])
print df_volume
print '\n---------------------- separate line--------------------\n'
df_2017 = aapl_table.loc['2016-10':'2017-04',['Open', 'High', 'Low', 'Close']].resample('M').agg(lambda x: x[-1])
print df_2017
</pre>
Using the methods we have already learned, we subset two DataFrames from the original one. Now we are going to merge the them with our DataFrame 'aapl_bar'
<pre class="prettyprint linenums">concat = pd.concat([aapl_bar,df_volume],axis = 1)
print concat
</pre>
By default the the DataFrame are joined with all of the data. This default options results in zero information loss. We can also merge them by intersection, this is called 'inner join':
<pre class="prettyprint linenums">concat = pd.concat([aapl_bar,df_volume],axis = 1, join = 'inner')
print concat
</pre>
Only the intersection part was left if use 'inner join' method.
Now let's try to append a DataFrame to another one:
<pre class="prettyprint linenums">append = aapl_bar.append(df_2017)
print append
</pre>
'Append' is essentially to concat two DataFrames by axis = 0, thus here is an alternative way to append:
<pre class="prettyprint linenums">concat = pd.concat([aapl_bar, df_2017], axis = 0)
print concat
</pre>
Please note that if the two DataFrame have some columns with the same column names, these columns are considered to be the same and will be merged. It's very important to have the right column names. If we change a column names here:
<pre class="prettyprint linenums">df_2017.columns = ['Change', 'High','Low','Close']
concat = pd.concat([aapl_bar, df_2017], axis = 0)
print concat
</pre>
Since the column name of 'Open' has been changed, the new DataFrame has an new column named 'Change'.
<h2>Summary</h2>
Hereby we introduced the most import part of python: resampling and DataFrame manipulation. We only introduced the most commonly used method in Financial data analysis. There are also many methods used in data mining, which are also beneficial. You can always check the <a href="https://pandas.pydata.org/pandas-docs/stable/index.html#">Pandas</a> official documentations for help.
